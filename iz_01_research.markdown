---
layout: page
title: Research
permalink: /research
---

## Publications

- **Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios**

   Jiaxuan Li, **Lang Yu**, Allyson Ettinger

   [[ACL 2023](https://aclanthology.org/2023.acl-short.70.pdf)]

- **Counterfactual reasoning: Do language models need world knowledge for causal understanding?**

   Jiaxuan Li, **Lang Yu**, Allyson Ettinger

   [[nCSI workshop at NeurIPS 2022](https://arxiv.org/abs/2212.03278)]

- **“No, They Did Not”: Dialogue Response Dynamics in Pre-trained Language Models**

   Sanghee J. Kim, **Lang Yu**, Allyson Ettinger

   [[COLING 2022](https://aclanthology.org/2022.coling-1.72/)]

- **Analyzing and Improving Compositionality in Neural Language Models**

   **Lang Yu**

   [[Phd Thesis](https://knowledge.uchicago.edu/record/3009)]

- **On the Interplay Between Fine-tuning and Composition in Transformers**

   **Lang Yu** and Allyson Ettinger

   [[Findings of ACL: ACL-IJCNLP 2021](https://arxiv.org/pdf/2105.14668.pdf)] [[Code](https://github.com/yulang/fine-tuning-and-composition-in-transformers)] [[Poster](files/acl_poster.pdf)]

- **Assessing Phrasal Representation and Composition in Transformers**

   **Lang Yu** and Allyson Ettinger

   [[EMNLP 2020](https://www.aclweb.org/anthology/2020.emnlp-main.397.pdf)] [[Code](https://github.com/yulang/phrasal-composition-in-transformers)] [[Talk](https://slideslive.com/38939299/assessing-phrasal-representation-and-composition-in-transformers)]


- **VinaSC: Scalable Autodock Vina with fine-grained scheduling on heterogeneous platform.**

   **Lang Yu**, Zhongzhi Luan, Xiangzheng Sun, Zhe Wang, and Hailong Yang

   [[BIBM 2016](https://ieeexplore.ieee.org/document/7822624)] [[Paper](files/vina.pdf)]
